{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXY+FGCO8ICU7COYVDw0X4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swathikuppala/Atoms/blob/main/embeddings_through_encoder_decoder_framework_(GCN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html"
      ],
      "metadata": {
        "id": "0IRqdl-UY1Y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c39f6ce-c76c-4a5b-c5cc-433d4a987239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/661.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/661.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/661.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=9d7785a12b724b2e7c99cd4a7a851b041361d005a95b7da55646a067287f167a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.2.0+pt20cpu torch_cluster-1.6.1+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu torch_spline_conv-1.2.2+pt20cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "N4fWLl3xZfng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the Google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY0OLpo_Zh8o",
        "outputId": "814d6cf0-740d-481f-fb61-0253e8a46104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headDir = \"drive/MyDrive/dataset/\"\n",
        "#headDir = \"../\""
      ],
      "metadata": {
        "id": "nCPfEeWKZjzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = headDir + \"andrea-juslin-dataGt100(2).npy\"\n",
        "data = np.load(path, allow_pickle=True)\n",
        "data = data[None][0]\n",
        "dataXorig = []\n",
        "dataY = []\n",
        "dataPe = []\n",
        "for x, y, z in zip(data['x'], data['y'], data['z']):\n",
        "  if y > 1: continue # We only want 0 and 1 labels for this activity\n",
        "  dataXorig.append(x)\n",
        "  dataY.append(y)\n",
        "  dataPe.append(z['pe'])"
      ],
      "metadata": {
        "id": "8QsPXHgQZn6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featLen = 30 # we are restricting to first thirty nearest neighbours\n",
        "dataAtoms = torch.tensor(np.array([x[0][:featLen+1] for x in dataXorig]), dtype=torch.float)\n",
        "dataX = torch.tensor(np.array([x[1][:featLen+1] for x in dataXorig]).reshape(len(dataAtoms),featLen+1,1), dtype=torch.float)\n",
        "dataY = torch.tensor(dataY, dtype=torch.long)\n",
        "#dataX = dataAtoms"
      ],
      "metadata": {
        "id": "QB-ijJ-UcqJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataXAll = torch.concat((dataX, dataAtoms), axis=2)"
      ],
      "metadata": {
        "id": "JqB2c-aYQ2qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataXAll.shape, dataX.shape, dataY.shape, dataAtoms.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avfljoELQpsV",
        "outputId": "45058062-0cfe-40d9-d8f7-9d676a62b99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3582, 31, 4]),\n",
              " torch.Size([3582, 31, 1]),\n",
              " torch.Size([3582]),\n",
              " torch.Size([3582, 31, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posData = []\n",
        "for dt, y in zip(dataAtoms, dataY):\n",
        "  data = Data(x= dt, pos=dt, y = y)#, pre_transform=T.RadiusGraph(r=4.0), transform=T.Distance())\n",
        "  data.validate(raise_on_error=True)\n",
        "  posData.append(data)"
      ],
      "metadata": {
        "id": "4RXmuuP3Q5eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distData = []\n",
        "for dt, x, y in zip(dataAtoms, dataX, dataY):\n",
        "  data = Data(x= x, pos=dt, y = y)#, pre_transform=T.RadiusGraph(r=4.0), transform=T.Distance())\n",
        "  data.validate(raise_on_error=True)\n",
        "  distData.append(data)"
      ],
      "metadata": {
        "id": "ynke0Q0CQ7hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allData = []\n",
        "for dt, x, y in zip(dataAtoms, dataXAll, dataY):\n",
        "  data = Data(x= x, pos=dt, y = y)#, pre_transform=T.RadiusGraph(r=4.0), transform=T.Distance())\n",
        "  data.validate(raise_on_error=True)\n",
        "  allData.append(data)"
      ],
      "metadata": {
        "id": "mFNL2g19Q_KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allData = posData"
      ],
      "metadata": {
        "id": "GbylGfrORCDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(InMemoryDataset):\n",
        "    def __init__(self, root, data_list, transform=None, pre_transform=None, pre_filter=None):\n",
        "        self.data_list = data_list\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['mydata']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        # Read data into huge `Data` list.\n",
        "        data_list = self.data_list\n",
        "\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "CK6Hgz_NRHBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(data)\n",
        "data.edge_weight"
      ],
      "metadata": {
        "id": "ynO4uda8RJC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "O0zuepok5h1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf ./data/processed/\n",
        "dataset = MyDataset(\"./data\",allData, transform=T.Compose([T.RadiusGraph(r=1.0), T.Distance(),T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      add_negative_train_samples=False),\n",
        "]))\n",
        "#dataset = MyDataset(\"./data\",allData, pre_transform=T.Compose([T.RadiusGraph(r=2.0), T.Distance()]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NJEPCRa4vKy",
        "outputId": "d37ee267-5524-464f-d7a5-22c684f34c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = dataset[0]"
      ],
      "metadata": {
        "id": "B7TyAqv_5SUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y6KsEI65SLE",
        "outputId": "b9a23b86-a3ff-4f01-b22f-550994a8bc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[111042, 3], y=[3582], pos=[111042, 3], edge_index=[2, 667386], edge_attr=[667386, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling"
      ],
      "metadata": {
        "id": "l8sFhMmL5nua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
        "\n",
        "\n",
        "model = Net(dataset.num_node_features, 128, dataset.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "0HuujJnV5amj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.x, train_data.edge_index, train_data.num_nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsK9-HPp59lL",
        "outputId": "42483205-adb2-44ac-a16e-aa70072c429b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 4.9373e-01, -5.0243e-01,  4.9416e-01],\n",
              "         [ 4.9772e-01,  5.0008e-01,  5.0076e-01],\n",
              "         [ 4.9486e-01, -4.9807e-01, -5.0623e-01],\n",
              "         [-5.0338e-01,  4.9722e-01,  5.0005e-01],\n",
              "         [ 4.9590e-01,  5.0237e-01, -5.0386e-01],\n",
              "         [-5.0824e-01,  4.9111e-01, -5.0395e-01],\n",
              "         [-5.0035e-01, -5.0338e-01,  5.0045e-01],\n",
              "         [-5.0382e-01, -4.9987e-01, -5.0158e-01],\n",
              "         [-7.6340e-03,  9.9569e-01,  2.3790e-04],\n",
              "         [-4.5994e-03, -2.4343e-03,  9.9725e-01],\n",
              "         [ 9.9891e-01, -3.8582e-03,  1.6801e-03],\n",
              "         [-1.0004e+00, -5.1671e-03,  2.2675e-03],\n",
              "         [-1.4050e-03, -6.5336e-03, -1.0009e+00],\n",
              "         [-3.7660e-03, -1.0029e+00, -2.3496e-03],\n",
              "         [-6.9563e-03,  9.8963e-01, -1.0010e+00],\n",
              "         [ 9.9740e-01, -6.2066e-03,  9.9767e-01],\n",
              "         [-1.0059e+00,  9.8958e-01, -4.8907e-04],\n",
              "         [ 9.9702e-01, -1.8703e-03, -1.0003e+00],\n",
              "         [ 9.9507e-01, -1.0030e+00, -6.6027e-03],\n",
              "         [ 5.6142e-04,  9.9790e-01,  1.0004e+00],\n",
              "         [ 1.0006e+00,  9.9830e-01,  2.3518e-03],\n",
              "         [-1.0034e+00, -3.5944e-03,  1.0006e+00],\n",
              "         [-1.0034e+00, -1.0016e+00, -1.2129e-03],\n",
              "         [-1.3494e-03, -1.0079e+00,  9.9769e-01],\n",
              "         [-6.4830e-04, -1.0047e+00, -1.0016e+00],\n",
              "         [-1.0057e+00, -1.2709e-02, -1.0008e+00],\n",
              "         [ 4.9431e-01,  1.4923e+00, -5.0269e-01],\n",
              "         [ 1.4957e+00,  4.9474e-01,  4.9517e-01],\n",
              "         [ 1.4911e+00,  5.0177e-01, -5.0285e-01],\n",
              "         [ 1.4933e+00, -5.0151e-01, -5.0237e-01]]),\n",
              " tensor([[ 2, 11,  2, 14,  3, 14, 11,  8,  2,  7,  6,  3,  9,  5,  1,  9,  5,  7,\n",
              "           6,  0, 12, 11,  0, 13,  7,  1,  0,  3,  5,  8, 21,  5,  6,  4, 13,  0,\n",
              "           1,  1,  0,  0,  2, 21,  2,  7, 16,  8,  3,  1,  6,  7,  5, 12,  1, 18,\n",
              "           3,  3, 21,  3,  0,  8,  2, 28,  4,  4,  6, 11,  0,  4,  8,  4, 10,  1,\n",
              "          13, 19, 12, 15,  0, 18,  6,  9, 16, 21, 19,  8, 23, 30, 23, 16, 10, 26,\n",
              "          18, 17, 11, 24, 27, 18, 24,  8,  7, 17, 29,  6, 18, 14,  7,  2, 19, 21,\n",
              "          14, 28, 27, 17, 20, 25,  4, 11, 19,  9, 11, 20, 29, 28, 12, 28, 25, 30,\n",
              "          14, 13, 22, 29, 23, 10, 30, 13, 25, 27, 14,  3, 12, 10, 29, 10,  9,  9,\n",
              "          28, 10, 22, 13, 17, 22, 16, 15, 30, 22, 27,  8, 29, 12],\n",
              "         [ 9, 16, 21, 19,  8, 23, 30, 23, 16, 10, 26, 18, 17, 11, 24, 27, 18, 24,\n",
              "           8,  7, 17, 29,  6, 18, 14,  7,  2, 19, 21, 14, 28, 27, 17, 20, 25,  4,\n",
              "          11, 19,  9, 11, 20, 29, 28, 12, 28, 25, 30, 14, 13, 22, 29, 23, 10, 30,\n",
              "          13, 25, 27, 14,  3, 12, 10, 29, 10,  9,  9, 28, 10, 22, 13, 17, 22, 16,\n",
              "          15, 30, 22, 27,  8, 29, 12,  2, 11,  2, 14,  3, 14, 11,  8,  2,  7,  6,\n",
              "           3,  9,  5,  1,  9,  5,  7,  6,  0, 12, 11,  0, 13,  7,  1,  0,  3,  5,\n",
              "           8, 21,  5,  6,  4, 13,  0,  1,  1,  0,  0,  2, 21,  2,  7, 16,  8,  3,\n",
              "           1,  6,  7,  5, 12,  1, 18,  3,  3, 21,  3,  0,  8,  2, 28,  4,  4,  6,\n",
              "          11,  0,  4,  8,  4, 10,  1, 13, 19, 12, 15,  0, 18,  6]]),\n",
              " 31)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "    # We perform a new round of negative sampling for every training epoch:\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "    # Concat positive and negative edge indices.\n",
        "    edge_label_index = torch.cat(\n",
        "        [train_data.edge_label_index, neg_edge_index],\n",
        "        dim=-1,\n",
        "    )\n",
        "    # Label for positive edges: 1, for negative edges: 0.\n",
        "    edge_label = torch.cat([\n",
        "        train_data.edge_label,\n",
        "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "    ], dim=0)\n",
        "\n",
        "    # Note: The model is trained in a supervised manner using the given\n",
        "    # `edge_label_index` and `edge_label` targets.\n",
        "    out = model.decode(z, edge_label_index).view(-1)\n",
        "    loss = criterion(out, edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "E7v0KrIP5x9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n",
        "# Train/Test Loop\n",
        "best_val_auc = final_test_auc = 0\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    val_auc = test(val_data)\n",
        "    test_auc = test(test_data)\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        final_test_auc = test_auc\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
        "          f'Test: {test_auc:.4f}')\n",
        "\n",
        "print(f'Final Test: {final_test_auc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73JXSGIV6UCU",
        "outputId": "5f555459-ac55-46b0-c493-e1a7920b4033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.6898, Val: 0.8125, Test: 0.6914\n",
            "Epoch: 002, Loss: 0.6812, Val: 0.8750, Test: 0.6790\n",
            "Epoch: 003, Loss: 0.6629, Val: 0.7500, Test: 0.6790\n",
            "Epoch: 004, Loss: 0.6491, Val: 0.6875, Test: 0.6667\n",
            "Epoch: 005, Loss: 0.6394, Val: 0.5000, Test: 0.6667\n",
            "Epoch: 006, Loss: 0.6204, Val: 0.5000, Test: 0.6296\n",
            "Epoch: 007, Loss: 0.5814, Val: 0.5000, Test: 0.5926\n",
            "Epoch: 008, Loss: 0.6037, Val: 0.5000, Test: 0.5679\n",
            "Epoch: 009, Loss: 0.5497, Val: 0.5000, Test: 0.5556\n",
            "Epoch: 010, Loss: 0.5821, Val: 0.5000, Test: 0.5432\n",
            "Epoch: 011, Loss: 0.6151, Val: 0.5625, Test: 0.5556\n",
            "Epoch: 012, Loss: 0.6047, Val: 0.5625, Test: 0.5802\n",
            "Epoch: 013, Loss: 0.5483, Val: 0.5625, Test: 0.5802\n",
            "Epoch: 014, Loss: 0.5652, Val: 0.5625, Test: 0.5556\n",
            "Epoch: 015, Loss: 0.5164, Val: 0.5625, Test: 0.5926\n",
            "Epoch: 016, Loss: 0.5794, Val: 0.5625, Test: 0.5926\n",
            "Epoch: 017, Loss: 0.5035, Val: 0.5625, Test: 0.6049\n",
            "Epoch: 018, Loss: 0.5395, Val: 0.5000, Test: 0.6173\n",
            "Epoch: 019, Loss: 0.5069, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 020, Loss: 0.4458, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 021, Loss: 0.4822, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 022, Loss: 0.5254, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 023, Loss: 0.4381, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 024, Loss: 0.4520, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 025, Loss: 0.5196, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 026, Loss: 0.5176, Val: 0.4375, Test: 0.5926\n",
            "Epoch: 027, Loss: 0.5581, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 028, Loss: 0.5218, Val: 0.4375, Test: 0.6914\n",
            "Epoch: 029, Loss: 0.4952, Val: 0.5625, Test: 0.6790\n",
            "Epoch: 030, Loss: 0.4630, Val: 0.5625, Test: 0.7284\n",
            "Epoch: 031, Loss: 0.4660, Val: 0.5000, Test: 0.7407\n",
            "Epoch: 032, Loss: 0.4551, Val: 0.5000, Test: 0.7407\n",
            "Epoch: 033, Loss: 0.4979, Val: 0.5625, Test: 0.7531\n",
            "Epoch: 034, Loss: 0.4842, Val: 0.5000, Test: 0.7037\n",
            "Epoch: 035, Loss: 0.4969, Val: 0.4375, Test: 0.6914\n",
            "Epoch: 036, Loss: 0.4835, Val: 0.4375, Test: 0.6667\n",
            "Epoch: 037, Loss: 0.4800, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 038, Loss: 0.5248, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 039, Loss: 0.4811, Val: 0.4375, Test: 0.5926\n",
            "Epoch: 040, Loss: 0.4021, Val: 0.4375, Test: 0.5926\n",
            "Epoch: 041, Loss: 0.5059, Val: 0.5000, Test: 0.6049\n",
            "Epoch: 042, Loss: 0.4643, Val: 0.5000, Test: 0.6049\n",
            "Epoch: 043, Loss: 0.5081, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 044, Loss: 0.4944, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 045, Loss: 0.4507, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 046, Loss: 0.5373, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 047, Loss: 0.4906, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 048, Loss: 0.5428, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 049, Loss: 0.4433, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 050, Loss: 0.4401, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 051, Loss: 0.4386, Val: 0.4375, Test: 0.6667\n",
            "Epoch: 052, Loss: 0.4834, Val: 0.4375, Test: 0.6790\n",
            "Epoch: 053, Loss: 0.5002, Val: 0.4375, Test: 0.7037\n",
            "Epoch: 054, Loss: 0.4669, Val: 0.4375, Test: 0.7037\n",
            "Epoch: 055, Loss: 0.5356, Val: 0.4375, Test: 0.6790\n",
            "Epoch: 056, Loss: 0.4877, Val: 0.4375, Test: 0.7037\n",
            "Epoch: 057, Loss: 0.4454, Val: 0.4375, Test: 0.6914\n",
            "Epoch: 058, Loss: 0.4895, Val: 0.4375, Test: 0.6667\n",
            "Epoch: 059, Loss: 0.4650, Val: 0.4375, Test: 0.6667\n",
            "Epoch: 060, Loss: 0.4335, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 061, Loss: 0.4776, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 062, Loss: 0.5085, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 063, Loss: 0.4278, Val: 0.4375, Test: 0.6173\n",
            "Epoch: 064, Loss: 0.4436, Val: 0.4375, Test: 0.5926\n",
            "Epoch: 065, Loss: 0.4058, Val: 0.4375, Test: 0.5679\n",
            "Epoch: 066, Loss: 0.5414, Val: 0.4375, Test: 0.5556\n",
            "Epoch: 067, Loss: 0.4950, Val: 0.4375, Test: 0.5926\n",
            "Epoch: 068, Loss: 0.4283, Val: 0.4375, Test: 0.6049\n",
            "Epoch: 069, Loss: 0.4796, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 070, Loss: 0.4727, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 071, Loss: 0.5308, Val: 0.4375, Test: 0.6667\n",
            "Epoch: 072, Loss: 0.5296, Val: 0.5000, Test: 0.6667\n",
            "Epoch: 073, Loss: 0.4807, Val: 0.5625, Test: 0.6667\n",
            "Epoch: 074, Loss: 0.4751, Val: 0.5000, Test: 0.7037\n",
            "Epoch: 075, Loss: 0.5058, Val: 0.5000, Test: 0.7160\n",
            "Epoch: 076, Loss: 0.4686, Val: 0.5000, Test: 0.7160\n",
            "Epoch: 077, Loss: 0.4399, Val: 0.5625, Test: 0.7037\n",
            "Epoch: 078, Loss: 0.4289, Val: 0.5625, Test: 0.6914\n",
            "Epoch: 079, Loss: 0.4933, Val: 0.5000, Test: 0.6914\n",
            "Epoch: 080, Loss: 0.4800, Val: 0.5000, Test: 0.6790\n",
            "Epoch: 081, Loss: 0.4456, Val: 0.5000, Test: 0.6543\n",
            "Epoch: 082, Loss: 0.4841, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 083, Loss: 0.4861, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 084, Loss: 0.4779, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 085, Loss: 0.4931, Val: 0.5000, Test: 0.6296\n",
            "Epoch: 086, Loss: 0.4417, Val: 0.5000, Test: 0.6173\n",
            "Epoch: 087, Loss: 0.4602, Val: 0.5000, Test: 0.6420\n",
            "Epoch: 088, Loss: 0.4848, Val: 0.5000, Test: 0.6543\n",
            "Epoch: 089, Loss: 0.4421, Val: 0.5000, Test: 0.6790\n",
            "Epoch: 090, Loss: 0.4796, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 091, Loss: 0.4489, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 092, Loss: 0.4591, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 093, Loss: 0.4048, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 094, Loss: 0.5290, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 095, Loss: 0.4828, Val: 0.4375, Test: 0.6296\n",
            "Epoch: 096, Loss: 0.5219, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 097, Loss: 0.4541, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 098, Loss: 0.4721, Val: 0.4375, Test: 0.6543\n",
            "Epoch: 099, Loss: 0.4633, Val: 0.4375, Test: 0.6420\n",
            "Epoch: 100, Loss: 0.4566, Val: 0.4375, Test: 0.6420\n",
            "Final Test: 0.6790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = model.encode(test_data.x, test_data.edge_index)\n",
        "final_edge_index = model.decode_all(z)\n"
      ],
      "metadata": {
        "id": "ycFY_ITu61xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiXDFK0T9Ml7",
        "outputId": "632b4756-6022-4c10-d33d-bee72e5d9e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([31, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB0OOiL19aiy",
        "outputId": "0b6578a2-8472-437c-cf6e-0dee6ce3c764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2006,  0.5993],\n",
              "        [ 1.0808,  0.3958],\n",
              "        [ 1.7738,  0.2527],\n",
              "        [-1.3969, -0.7702],\n",
              "        [ 0.6044,  1.4926],\n",
              "        [ 0.3546, -1.2677],\n",
              "        [-1.0674,  0.7304],\n",
              "        [ 0.4989,  1.3687],\n",
              "        [-1.8316,  0.3944],\n",
              "        [ 0.3855,  0.4681],\n",
              "        [ 0.9900,  1.2023],\n",
              "        [ 1.3051, -1.0147],\n",
              "        [-0.6511,  1.3192],\n",
              "        [-1.6022, -0.8433],\n",
              "        [-0.6098,  0.2953],\n",
              "        [-0.6706, -0.6197],\n",
              "        [ 1.8986, -0.3647],\n",
              "        [-0.1846,  1.1360],\n",
              "        [-0.5961, -1.4654],\n",
              "        [-0.0329, -0.6400],\n",
              "        [ 1.0961,  0.8424],\n",
              "        [ 1.3997, -1.0634],\n",
              "        [ 0.3315,  1.4598],\n",
              "        [-0.9722,  0.6993],\n",
              "        [ 0.8069,  0.7934],\n",
              "        [-1.6752, -0.4596],\n",
              "        [-1.2179,  0.3345],\n",
              "        [ 0.2456, -0.7085],\n",
              "        [ 1.9910, -0.9511],\n",
              "        [ 1.0780, -1.4862],\n",
              "        [-0.3308, -1.2393]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9VESuFQ64Lv",
        "outputId": "323a9c94-3a4e-41b7-d62d-71d4101d4ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,\n",
              "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,\n",
              "          4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,\n",
              "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
              "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n",
              "          8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "          9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "         10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
              "         11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
              "         12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
              "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15,\n",
              "         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16,\n",
              "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17,\n",
              "         17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "         18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
              "         19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21,\n",
              "         21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
              "         22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
              "         23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24,\n",
              "         24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
              "         25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27,\n",
              "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "         28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "         29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
              "         30],\n",
              "        [ 0,  1,  2,  4,  6,  7,  8,  9, 10, 12, 14, 16, 17, 19, 20, 22, 23, 24,\n",
              "         26,  0,  1,  2,  3,  7, 10, 11, 12, 14, 16, 19, 22, 23, 24, 28, 29, 30,\n",
              "          0,  1,  2,  4,  7,  9, 10, 11, 16, 17, 20, 21, 22, 24, 28, 29,  1,  3,\n",
              "          8, 11, 13, 14, 18, 19, 23, 25, 26, 30,  0,  2,  4,  6,  7,  8,  9, 10,\n",
              "         12, 17, 20, 22, 23, 26,  5, 11, 13, 15, 18, 21, 27, 28, 29, 30,  0,  4,\n",
              "          6,  8,  9, 12, 13, 15, 17, 20, 22, 23, 25, 26, 27,  0,  1,  2,  4,  7,\n",
              "         10, 11, 12, 14, 16, 19, 20, 22, 23, 24, 28,  0,  3,  4,  6,  8, 12, 13,\n",
              "         14, 15, 17, 18, 19, 22, 23, 25, 26, 30,  0,  2,  4,  6,  9, 10, 12, 15,\n",
              "         17, 20, 21, 22, 26, 27,  0,  1,  2,  4,  7,  9, 10, 11, 12, 14, 16, 17,\n",
              "         19, 20, 22, 23, 24, 28,  1,  2,  3,  5,  7, 10, 11, 14, 16, 18, 19, 21,\n",
              "         24, 28, 29, 30,  0,  1,  4,  6,  7,  8,  9, 10, 12, 14, 17, 20, 22, 23,\n",
              "         24, 25, 26,  3,  5,  6,  8, 13, 14, 15, 18, 19, 23, 25, 26, 27, 30,  0,\n",
              "          1,  3,  7,  8, 10, 11, 12, 13, 14, 16, 18, 19, 22, 23, 24, 25, 30,  5,\n",
              "          6,  8,  9, 13, 15, 17, 18, 21, 25, 26, 27, 29,  0,  1,  2,  7, 10, 11,\n",
              "         14, 16, 19, 20, 21, 22, 24, 28, 29, 30,  0,  2,  4,  6,  8,  9, 10, 12,\n",
              "         15, 17, 20, 22, 23, 26, 27,  3,  5,  8, 11, 13, 14, 15, 18, 19, 25, 28,\n",
              "         29, 30,  0,  1,  3,  7,  8, 10, 11, 13, 14, 16, 18, 19, 23, 24, 25, 28,\n",
              "         29, 30,  0,  2,  4,  6,  7,  9, 10, 12, 16, 17, 20, 21, 22, 28,  2,  5,\n",
              "          9, 11, 15, 16, 20, 21, 27, 28, 29,  0,  1,  2,  4,  6,  7,  8,  9, 10,\n",
              "         12, 14, 16, 17, 20, 22, 23, 24, 26,  0,  1,  3,  4,  6,  7,  8, 10, 12,\n",
              "         13, 14, 17, 19, 22, 23, 24, 25, 26, 30,  0,  1,  2,  7, 10, 11, 12, 14,\n",
              "         16, 19, 22, 23, 24, 28, 30,  3,  6,  8, 12, 13, 14, 15, 18, 19, 23, 25,\n",
              "         26, 30,  0,  3,  4,  6,  8,  9, 12, 13, 15, 17, 22, 23, 25, 26, 27,  5,\n",
              "          6,  9, 13, 15, 17, 21, 26, 27, 28, 29,  1,  2,  5,  7, 10, 11, 16, 18,\n",
              "         19, 20, 21, 24, 27, 28, 29, 30,  1,  2,  5, 11, 15, 16, 18, 19, 21, 27,\n",
              "         28, 29, 30,  1,  3,  5,  8, 11, 13, 14, 16, 18, 19, 23, 24, 25, 28, 29,\n",
              "         30]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Assuming 'z' contains your node embeddings\n",
        "node_embeddings = z.cpu().numpy()  # Convert to NumPy array if it's a PyTorch tensor\n",
        "\n",
        "# Apply t-SNE to reduce dimensionality\n",
        "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
        "embeddings_2d = tsne.fit_transform(node_embeddings)\n",
        "\n",
        "# Create a scatter plot for visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], marker='o', s=20)\n",
        "plt.title('t-SNE Visualization of Node Embeddings')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "BedNpor9H41h",
        "outputId": "4ad145ae-0add-40ff-cb07-9b14465daea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e7bdd2d5bb5a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming 'z' contains your node embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnode_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to NumPy array if it's a PyTorch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Apply t-SNE to reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
          ]
        }
      ]
    }
  ]
}